{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ad1d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T22:43:30.136072Z",
     "iopub.status.busy": "2023-05-10T22:43:30.136072Z",
     "iopub.status.idle": "2023-05-10T22:43:30.831327Z",
     "shell.execute_reply": "2023-05-10T22:43:30.831327Z",
     "shell.execute_reply.started": "2023-05-10T22:43:30.136072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b7f2f",
   "metadata": {},
   "source": [
    "# Tier 1 matching - 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c410c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T22:43:36.284982Z",
     "iopub.status.busy": "2023-05-10T22:43:36.284982Z",
     "iopub.status.idle": "2023-05-10T22:43:36.505209Z",
     "shell.execute_reply": "2023-05-10T22:43:36.504610Z",
     "shell.execute_reply.started": "2023-05-10T22:43:36.284982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from dfply import *\n",
    "import Levenshtein as lev\n",
    "from metaphone import doublemetaphone\n",
    "import geopy\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8994ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting metaphone\n",
      "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
      "Building wheels for collected packages: metaphone\n",
      "  Building wheel for metaphone (setup.py): started\n",
      "  Building wheel for metaphone (setup.py): finished with status 'done'\n",
      "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13918 sha256=f065422030498e15fe4060fffd691e50b70179e8168e271b96bba0fb4b36d113\n",
      "  Stored in directory: c:\\users\\yanjiacao\\appdata\\local\\pip\\cache\\wheels\\b2\\9e\\d9\\26be7687b8fe36cd6cacbec34e825a3dbcd3bae54017cfb385\n",
      "Successfully built metaphone\n",
      "Installing collected packages: metaphone\n",
      "Successfully installed metaphone-0.6\n"
     ]
    }
   ],
   "source": [
    "# ! pip install metaphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a9618",
   "metadata": {},
   "source": [
    "### 1. Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dafce01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:25.082014Z",
     "iopub.status.busy": "2023-05-09T05:37:25.081016Z",
     "iopub.status.idle": "2023-05-09T05:37:25.093042Z",
     "shell.execute_reply": "2023-05-09T05:37:25.093042Z",
     "shell.execute_reply.started": "2023-05-09T05:37:25.082014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_gov_esri = {\n",
    "    'base_set'  : 'gov',\n",
    "    'target_set': 'esri',\n",
    "    'spatial_join_1000_file': \"gov_esri1000m.csv\",\n",
    "    'gps_list'  : ['E_LAT','E_LONG','G_LAT','G_LONG'],\n",
    "    'name_list' : ['E_NAME','G_NAME'],\n",
    "    'base_ID'   : 'G_RECORDID',\n",
    "    'target_ID' : 'E_RECORDID'\n",
    "}  \n",
    "\n",
    "config_gov_yelp = {\n",
    "    'base_set'  : 'gov',\n",
    "    'target_set': 'yelp',\n",
    "    'spatial_join_1000_file': \"gov_yelp1000m.csv\",\n",
    "    'gps_list'  : ['Y_LAT','Y_LONG','G_LAT','G_LONG'],\n",
    "    'name_list' : ['Y_NAME','G_NAME'],\n",
    "    'base_ID'   : 'Y_RECORDID',\n",
    "    'target_ID' : 'G_RECORDID'\n",
    "}   \n",
    "\n",
    "config_esri_yelp = {\n",
    "    'base_set'  : 'esri',\n",
    "    'target_set': 'yelp',\n",
    "    'spatial_join_1000_file': \"esri_yelp1000m.csv\",\n",
    "    'gps_list'  : ['Y_LAT','Y_LONG','E_LAT','E_LONG'],\n",
    "    'name_list' : ['Y_NAME','E_NAME'],\n",
    "    'base_ID'   : 'E_RECORDID',\n",
    "    'target_ID' : 'Y_RECORDID'\n",
    "}\n",
    "\n",
    "\n",
    "####-----------------------------------------\n",
    "#### Set up config\n",
    "# config = config_gov_yelp  ### CHANGE THIS\n",
    "# config = config_gov_esri  ### CHANGE THIS\n",
    "config = config_esri_yelp  ### CHANGE THIS\n",
    "####-----------------------------------------\n",
    "\n",
    "\n",
    "input_file = config['spatial_join_1000_file']\n",
    "gps_list   = config['gps_list']\n",
    "name_list  = config['name_list']\n",
    "base_ID    = config['base_ID']\n",
    "target_ID  = config['target_ID']\n",
    "\n",
    "gps_threshold = 100 #meters\n",
    "lev_dist_threshold = 4\n",
    "dm_threshold = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155da7c",
   "metadata": {},
   "source": [
    "### 2. Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9b8dc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:27.302992Z",
     "iopub.status.busy": "2023-05-09T05:37:27.301995Z",
     "iopub.status.idle": "2023-05-09T05:37:31.405932Z",
     "shell.execute_reply": "2023-05-09T05:37:31.404935Z",
     "shell.execute_reply.started": "2023-05-09T05:37:27.302992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(925329, 33)\n",
      "(10790,)\n"
     ]
    }
   ],
   "source": [
    "#### Read Data \n",
    "#data candidates: gov_esri1000m, gov_yelp1000m, esri_yelp1000m\n",
    "join_table=pd.read_csv(input_file)\n",
    "\n",
    "#### Assign unique ID to Base-ID and Target-ID\n",
    "join_table['Base_ID_int'] = join_table.groupby([base_ID], sort=False).ngroup()\n",
    "join_table['Target_ID_int'] = join_table.groupby([target_ID], sort=False).ngroup()\n",
    "\n",
    "#### Define distance functions \n",
    "def great_circle_dist(lat_a, lng_a, lat_b, lng_b, metric='meter'):\n",
    "    try:\n",
    "        if metric == 'meter':\n",
    "            point_a = (lat_a, lng_a)\n",
    "            point_b = (lat_b, lng_b)\n",
    "            return great_circle(point_a, point_b).meters\n",
    "        elif metric == 'km':\n",
    "            point_a = (lat_a, lng_a)\n",
    "            point_b = (lat_b, lng_b)\n",
    "            return great_circle(point_a, point_b).km\n",
    "        elif metric == 'mile':\n",
    "            point_a = (lat_a, lng_a)\n",
    "            point_b = (lat_b, lng_b)\n",
    "            return great_circle(point_a, point_b).miles\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "print (join_table.shape)\n",
    "print (join_table[base_ID].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b17cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean white space for leading and tail of names\n",
    "join_table[name_list[0]] = join_table[name_list[0]].apply(lambda x: str(x).strip())\n",
    "join_table[name_list[1]] = join_table[name_list[1]].apply(lambda x: str(x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9029dfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:31.407928Z",
     "iopub.status.busy": "2023-05-09T05:37:31.406939Z",
     "iopub.status.idle": "2023-05-09T05:37:56.507252Z",
     "shell.execute_reply": "2023-05-09T05:37:56.507252Z",
     "shell.execute_reply.started": "2023-05-09T05:37:31.407928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Matching Process\n",
    "\n",
    "# Step 1 - location match: remove food outlet from base (left side) where no target food outlet were within spatial join radius (1000m)\n",
    "join_table = join_table.loc[join_table.Join_Count >0]\n",
    "\n",
    "# Step 2 - GPS match: remove target food outlets > 'gps_threshold' (100m) away\n",
    "join_table['dist_dff'] = join_table.apply(lambda x: great_circle_dist(x[gps_list[2]],x[gps_list[3]],x[gps_list[0]],x[gps_list[1]],metric='meter'), axis=1) \n",
    "join_table = join_table.loc[join_table['dist_dff'] <= gps_threshold]\n",
    "\n",
    "# Step 3 - Store name match: remove outlet with Levenshtein > 'lev_dist_threshold'\n",
    "join_table['lev_dist'] = join_table.apply(lambda x: lev.distance(x[name_list[0]],  x[name_list[1]]), axis=1)\n",
    "join_table = join_table.loc[join_table['lev_dist'] <= lev_dist_threshold] \n",
    "\n",
    "# Step 4 - DM distance match: remove outlet with DM Dist > 'dm_threshold'\n",
    "join_table['DM1'] = join_table.apply(lambda x: doublemetaphone(str(x[name_list[0]]))[0], axis=1)\n",
    "join_table['DM2'] = join_table.apply(lambda x: doublemetaphone(str(x[name_list[1]]))[0], axis=1)\n",
    "join_table['DM_lev'] = join_table.apply(lambda x: lev.distance(x['DM1'],  x['DM2']), axis=1)\n",
    "join_table = join_table.loc[join_table['DM_lev'] <= dm_threshold] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8da1d80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:56.509242Z",
     "iopub.status.busy": "2023-05-09T05:37:56.509242Z",
     "iopub.status.idle": "2023-05-09T05:37:56.522942Z",
     "shell.execute_reply": "2023-05-09T05:37:56.522942Z",
     "shell.execute_reply.started": "2023-05-09T05:37:56.509242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total target POIs after Name Match: 4242\n",
      "Duplicated base POIs   (left side):  43\n",
      "Duplicated target POIs (right side): 38\n",
      "Duplicated base POIs   (left side):  43\n",
      "Duplicated target POIs (right side): 38\n"
     ]
    }
   ],
   "source": [
    "#unique number of POIs after name matching\n",
    "print(f\"Total target POIs after Name Match: {len(join_table[target_ID].unique())}\")\n",
    "\n",
    "# duplicated POIs in the target set (right side)\n",
    "print (f\"Duplicated base POIs   (left side):  {join_table.duplicated('Base_ID_int').sum()}\")\n",
    "print (f\"Duplicated target POIs (right side): {join_table.duplicated('Target_ID_int').sum()}\")\n",
    "\n",
    "print (f\"Duplicated base POIs   (left side):  {join_table.duplicated(subset=base_ID, keep='first').sum()}\")\n",
    "print (f\"Duplicated target POIs (right side): {join_table.duplicated(subset=target_ID, keep='first').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa5d02df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:56.524936Z",
     "iopub.status.busy": "2023-05-09T05:37:56.524936Z",
     "iopub.status.idle": "2023-05-09T05:37:56.538900Z",
     "shell.execute_reply": "2023-05-09T05:37:56.538900Z",
     "shell.execute_reply.started": "2023-05-09T05:37:56.524936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4280, 38)\n",
      "(4237,)\n"
     ]
    }
   ],
   "source": [
    "print (join_table.shape)\n",
    "print (join_table.Base_ID_int.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8406606",
   "metadata": {},
   "source": [
    "### 3. Cleaning duplicates of the Target food oulet  (right side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2744b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T05:37:56.540892Z",
     "iopub.status.busy": "2023-05-09T05:37:56.539895Z",
     "iopub.status.idle": "2023-05-09T05:37:57.073455Z",
     "shell.execute_reply": "2023-05-09T05:37:57.073455Z",
     "shell.execute_reply.started": "2023-05-09T05:37:56.540892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Esri & Yelp\n"
     ]
    }
   ],
   "source": [
    "#######Extra steps for Gov & ESRI Match\n",
    "#extra steps for cleaning duplicates for esri gas stations and similar names using smaller lev index\n",
    "if (config['base_set'] == 'gov') and (config['target_set'] == 'esri'):\n",
    "    print (\"Working on: Gov & ESRI\")\n",
    "    \n",
    "    ## Drop records where NAICS=447190  (Other Gasoline Stations)\n",
    "    ## Drop records where NAICS=457110/457120  (Gasoline Stations with Convenience Stores / Other Gasoline Stations)\n",
    "    join_table = join_table.loc[~(join_table['E_NAICS'].astype('str').str.startswith('44719')) & ~(join_table['E_NAICS'].astype('str').str.startswith('45711'))]\n",
    "    \n",
    "    #step 1 (Base ): If duplicate in RECORDID, then keep the one with lower lev score\n",
    "    # keep_base_IDs = join_table.groupby(['G_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_base_IDs = join_table.groupby(['Base_ID_int'])['lev_dist'].idxmin()\n",
    "    #step 2 (Target): If duplicate in RECORDID, then keep the one with lower lev score\n",
    "    # keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['E_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['Target_ID_int'])['lev_dist'].idxmin()\n",
    "    \n",
    "    #save processed data\n",
    "    gov_esri_match_final = join_table.loc[keep_target_IDs]\n",
    "    gov_esri_match_final.to_csv('gov_esri_tier1_for3match_20230512.csv',index=False)\n",
    "    \n",
    "\n",
    "#######Extra steps for Gov & Yelp Match\n",
    "if (config['base_set'] == 'gov') and (config['target_set'] == 'yelp'):\n",
    "    print (\"Working on: Gov & Yelp\")\n",
    "\n",
    "    #step 1 (Base)  : If duplicate in Base RECORDID, then keep the one with lower lev score\n",
    "    # keep_base_IDs   = join_table.groupby(['G_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_base_IDs   = join_table.groupby(['Base_ID_int'])['lev_dist'].idxmin()\n",
    "    #step 2 (Target): If duplicate in RECORDID, then keep the one with lower lev score\n",
    "    # keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['Y_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['Target_ID_int'])['lev_dist'].idxmin()\n",
    "    \n",
    "    #save processed data\n",
    "    gov_yelp_match_final = join_table.loc[keep_target_IDs]\n",
    "    gov_yelp_match_final.to_csv('gov_yelp_tier1_for3match_20230512.csv',index=False)\n",
    "    \n",
    "    \n",
    "#######Extra steps for Esri & Yelp Match\n",
    "if (config['base_set'] == 'esri') and (config['target_set'] == 'yelp'):\n",
    "    print (\"Working on: Esri & Yelp\")\n",
    "    \n",
    "    #step 1 (Base)  : If duplicate in Base RECORDID, then keep the one with lower lev score\n",
    "    # keep_base_IDs   = join_table.groupby(['E_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_base_IDs   = join_table.groupby(['Base_ID_int'])['lev_dist'].idxmin()\n",
    "    #step 2 (Target): If duplicate in Target RECORDID, then keep the one with lower lev score\n",
    "    keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['Y_RECORDID'])['lev_dist'].idxmin()\n",
    "    keep_target_IDs = join_table.loc[keep_base_IDs].groupby(['Target_ID_int'])['lev_dist'].idxmin()\n",
    "    \n",
    "    #save processed data\n",
    "    esri_yelp_match_final = join_table.loc[keep_target_IDs]\n",
    "    esri_yelp_match_final.to_csv('esri_yelp_tier1_for3match_20230512.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40744ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T22:45:05.671869Z",
     "iopub.status.busy": "2023-05-10T22:45:05.671869Z",
     "iopub.status.idle": "2023-05-10T22:45:05.687825Z",
     "shell.execute_reply": "2023-05-10T22:45:05.686827Z",
     "shell.execute_reply.started": "2023-05-10T22:45:05.671869Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gov_esri_match  : 2688\n",
      "gov_yelp_match  : 3485\n",
      "esri_yelp_match : 4208\n"
     ]
    }
   ],
   "source": [
    "print (f\"gov_esri_match  : {gov_esri_match_final.shape[0]}\")\n",
    "print (f\"gov_yelp_match  : {gov_yelp_match_final.shape[0]}\")\n",
    "print (f\"esri_yelp_match : {esri_yelp_match_final.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c87e0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3485"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gov_yelp_match_final['G_RECORDID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f506d",
   "metadata": {},
   "source": [
    "### 4. Matching 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10dfe76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:29:15.289304Z",
     "iopub.status.busy": "2023-05-11T01:29:15.288307Z",
     "iopub.status.idle": "2023-05-11T01:29:15.380280Z",
     "shell.execute_reply": "2023-05-11T01:29:15.379283Z",
     "shell.execute_reply.started": "2023-05-11T01:29:15.289304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gov_esri_match_final = pd.read_csv('gov_esri_tier1_for3match_20230512.csv')\n",
    "gov_yelp_match_final = pd.read_csv('gov_yelp_tier1_for3match_20230512.csv')\n",
    "esri_yelp_match_final = pd.read_csv('esri_yelp_tier1_for3match_20230512.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0312dfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:29:16.654605Z",
     "iopub.status.busy": "2023-05-11T01:29:16.653608Z",
     "iopub.status.idle": "2023-05-11T01:29:16.671560Z",
     "shell.execute_reply": "2023-05-11T01:29:16.670562Z",
     "shell.execute_reply.started": "2023-05-11T01:29:16.654605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_GE = ['G_NAME','G_RECORDID','E_NAME','E_RECORDID']\n",
    "cols_GY = ['G_NAME','G_RECORDID','Y_NAME','Y_RECORDID']\n",
    "cols_EY = ['E_NAME','E_RECORDID','Y_NAME','Y_RECORDID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c320fc26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:29:48.811230Z",
     "iopub.status.busy": "2023-05-11T01:29:48.810233Z",
     "iopub.status.idle": "2023-05-11T01:29:48.847131Z",
     "shell.execute_reply": "2023-05-11T01:29:48.846135Z",
     "shell.execute_reply.started": "2023-05-11T01:29:48.811230Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2069\n",
      "2072\n",
      "2118\n"
     ]
    }
   ],
   "source": [
    "### gov-esri-yelp  (gov_esri + gov_yelp)\n",
    "tier1_3way_v1 = gov_esri_match_final[cols_GE].merge(gov_yelp_match_final[cols_GY],on=['G_RECORDID','G_NAME'],how='inner')\n",
    "print (len(tier1_3way_v1))\n",
    "\n",
    "### gov_esri_yelp  (gov_esri + esri_yelp)\n",
    "tier1_3way_v2 = gov_esri_match_final[cols_GE].merge(esri_yelp_match_final[cols_EY],on=['E_RECORDID','E_NAME'],how='inner')\n",
    "print (len(tier1_3way_v2))\n",
    "\n",
    "### gov_esri_yelp  (gov_yelp + esri_yelp)\n",
    "tier1_3way_v3 = gov_yelp_match_final[cols_GY].merge(esri_yelp_match_final[cols_EY],on=['Y_RECORDID','Y_NAME'],how='inner')\n",
    "print (len(tier1_3way_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1e5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:29:55.488939Z",
     "iopub.status.busy": "2023-05-11T01:29:55.488939Z",
     "iopub.status.idle": "2023-05-11T01:29:55.498912Z",
     "shell.execute_reply": "2023-05-11T01:29:55.498912Z",
     "shell.execute_reply.started": "2023-05-11T01:29:55.488939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge all three combinations\n",
    "tier1_3way_all=pd.concat([tier1_3way_v1, tier1_3way_v2, tier1_3way_v3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15041632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:30:25.380827Z",
     "iopub.status.busy": "2023-05-11T01:30:25.379829Z",
     "iopub.status.idle": "2023-05-11T01:30:25.397336Z",
     "shell.execute_reply": "2023-05-11T01:30:25.397336Z",
     "shell.execute_reply.started": "2023-05-11T01:30:25.380827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n"
     ]
    }
   ],
   "source": [
    "### Drop duplicates if all columns are the same\n",
    "tier1_3way_final = tier1_3way_all.drop_duplicates()\n",
    "print (len(tier1_3way_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799879a1",
   "metadata": {},
   "source": [
    "### 5. Further drop duplicates coming from different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b718a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if there are duplicates based on G_RECORDID\n",
    "tier1_3way_final[tier1_3way_final.duplicated(['G_RECORDID'], keep=False)].sort_values(['G_RECORDID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666455f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:30:27.434098Z",
     "iopub.status.busy": "2023-05-11T01:30:27.434098Z",
     "iopub.status.idle": "2023-05-11T01:30:27.511908Z",
     "shell.execute_reply": "2023-05-11T01:30:27.511908Z",
     "shell.execute_reply.started": "2023-05-11T01:30:27.434098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Calculate \n",
    "tier1_3way_final['lev_dist_GE'] = tier1_3way_final.copy().apply(lambda x: lev.distance(x['G_NAME'],  str(x['E_NAME'])), axis=1)\n",
    "tier1_3way_final['lev_dist_GY'] = tier1_3way_final.copy().apply(lambda x: lev.distance(x['G_NAME'],  x['Y_NAME']), axis=1)\n",
    "tier1_3way_final['lev_dist_EY'] = tier1_3way_final.copy().apply(lambda x: lev.distance(str(x['E_NAME']),  x['Y_NAME']), axis=1)\n",
    "tier1_3way_final['lev_dist_score'] = tier1_3way_final['lev_dist_GE'] + tier1_3way_final['lev_dist_GY'] + tier1_3way_final['lev_dist_EY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2c693a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:30:50.624379Z",
     "iopub.status.busy": "2023-05-11T01:30:50.624379Z",
     "iopub.status.idle": "2023-05-11T01:30:50.647317Z",
     "shell.execute_reply": "2023-05-11T01:30:50.646318Z",
     "shell.execute_reply.started": "2023-05-11T01:30:50.624379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Use G-E to clean Y\n",
    "Y_lev = tier1_3way_final.groupby(['G_RECORDID','E_RECORDID']).lev_dist_score.transform(min)\n",
    "tier1_3way_final_clean = tier1_3way_final.loc[tier1_3way_final.lev_dist_score == Y_lev]\n",
    "\n",
    "### Use G-Y to clean E\n",
    "E_lev = tier1_3way_final_clean.groupby(['G_RECORDID','Y_RECORDID']).lev_dist_score.transform(min)\n",
    "tier1_3way_final_clean = tier1_3way_final_clean.loc[tier1_3way_final_clean.lev_dist_score == E_lev]\n",
    "\n",
    "### Use E-Y to clean G\n",
    "G_lev = tier1_3way_final_clean.groupby(['E_RECORDID','Y_RECORDID']).lev_dist_score.transform(min)\n",
    "tier1_3way_final_clean = tier1_3way_final_clean.loc[tier1_3way_final_clean.lev_dist_score == G_lev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "817fdc53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:31:12.640828Z",
     "iopub.status.busy": "2023-05-11T01:31:12.640828Z",
     "iopub.status.idle": "2023-05-11T01:31:12.663770Z",
     "shell.execute_reply": "2023-05-11T01:31:12.662772Z",
     "shell.execute_reply.started": "2023-05-11T01:31:12.640828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tier1_3way_final_clean.to_csv('tier1_3match_20230512.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf36d2e",
   "metadata": {},
   "source": [
    "### 6. Prepare data for Tier 1 2-way matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7260aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 3 match from each of the original data, prep for 2 match\n",
    "tier1_3way_final_clean=pd.read_csv('tier1_3match_20230512.csv')\n",
    "\n",
    "#read original data\n",
    "gov_all=pd.read_csv(\"gov_clean_final.csv\")\n",
    "esri_all=pd.read_csv(\"esri_clean_final.csv\")\n",
    "yelp_all=pd.read_csv(\"yelp_clean_final.csv\")\n",
    "\n",
    "gov_tier1_for_2match=gov_all.loc[~gov_all['G_RECORDID'].isin(tier1_3way_final_clean['G_RECORDID'])]\n",
    "esri_tier1_for_2match=esri_all.loc[~esri_all['E_RECORDID'].isin(tier1_3way_final_clean['E_RECORDID'])]\n",
    "yelp_tier1_for_2match=yelp_all.loc[~yelp_all['Y_RECORDID'].isin(tier1_3way_final_clean['Y_RECORDID'])]\n",
    "\n",
    "gov_tier1_for_2match.to_csv('gov_for_tier1_2match_0512.csv')\n",
    "esri_tier1_for_2match.to_csv('esri_for_tier1_2match_0512.csv')\n",
    "yelp_tier1_for_2match.to_csv('yelp_for_tier1_2match_0512.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
